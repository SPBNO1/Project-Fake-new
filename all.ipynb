{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b64bcd-cb86-4007-afd3-9f9f5e18cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.11/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.11/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from keras) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from optree->keras) (4.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: pythainlp in /opt/conda/lib/python3.11/site-packages (5.0.4)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.11/site-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2023.7.22)\n",
      "Requirement already satisfied: full in /opt/conda/lib/python3.11/site-packages (0.0.3.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from full) (2.3.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from full) (4.40.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->full) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->full) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->full) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->full) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->full) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->full) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (2024.4.28)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers->full) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers->full) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->full) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->full) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->full) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->full) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->full) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->full) (1.3.0)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.11/site-packages (2.11.1)\n",
      "Requirement already satisfied: attacut in /opt/conda/lib/python3.11/site-packages (1.0.6)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.11/site-packages (from attacut) (0.6.2)\n",
      "Requirement already satisfied: fire>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from attacut) (0.6.0)\n",
      "Requirement already satisfied: nptyping>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from attacut) (2.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from attacut) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1.2 in /opt/conda/lib/python3.11/site-packages (from attacut) (6.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from attacut) (1.16.0)\n",
      "Requirement already satisfied: ssg>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from attacut) (0.0.8)\n",
      "Requirement already satisfied: torch>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from attacut) (2.3.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (from fire>=0.1.3->attacut) (2.4.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in /opt/conda/lib/python3.11/site-packages (from ssg>=0.0.4->attacut) (0.9.10)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in /opt/conda/lib/python3.11/site-packages (from ssg>=0.0.4->attacut) (4.66.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.2.0->attacut) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.2.0->attacut) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.2.0->attacut) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install pythainlp\n",
    "!pip install full\n",
    "!pip install emoji\n",
    "!pip install attacut\n",
    "import tensorflow\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM,Bidirectional, Embedding, Dropout,BatchNormalization\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pythainlp\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "from pythainlp.util import normalize\n",
    "from pythainlp.tokenize import newmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5959f0-3532-4686-ba52-bd264a1ebd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('csv/x_train.csv',encoding='utf-8')\n",
    "x_test = pd.read_csv('csv/x_test.csv',encoding='utf-8')\n",
    "y_train = pd.read_csv('csv/y_train.csv',encoding='utf-8')\n",
    "y_test = pd.read_csv('csv/y_test.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea63e193-6f7b-4045-803d-36253dac7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('model/w2v_model2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d39c3e-993a-4afc-90db-d47d0db5ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(sentences):\n",
    "    tokenized_sentences = []\n",
    "    cleaned_sentences = []  # เพิ่มคอลัมน์เก็บประโยคที่ทำความสะอาดแล้ว\n",
    "    \n",
    "    for txt in sentences:\n",
    "        # แปลงเป็น string\n",
    "        t = str(txt)\n",
    "\n",
    "        # ลบตัวอักษรที่ไม่ใช่ภาษาไทย\n",
    "        cleaned_text = re.sub('[^ก-๙]', '', t)\n",
    "\n",
    "        # Normalize ข้อความ (เช่น การปรับสระให้เป็นรูปแบบเดียวกัน)\n",
    "        normalized_text = normalize(cleaned_text)\n",
    "\n",
    "        # ดึง stopwords ภาษาไทย\n",
    "        stop_words = set(thai_stopwords())\n",
    "\n",
    "        # ตัดคำโดยใช้ engine \"newmm\" สำหรับการตัดคำภาษาไทย\n",
    "        words = word_tokenize(normalized_text, engine=\"newmm\")\n",
    "\n",
    "        # ลบ stopwords และคำที่มีช่องว่าง\n",
    "        filtered_words = [word for word in words if word not in stop_words and word.strip()]\n",
    "\n",
    "        # แปลงเป็น lowercase\n",
    "        tokenized_sentence = [word.lower() for word in filtered_words]\n",
    "\n",
    "        # เก็บผลลัพธ์ของการตัดคำ\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "        # เก็บผลลัพธ์ของประโยคที่ทำความสะอาดแล้ว\n",
    "        cleaned_sentence = \" \".join(tokenized_sentence)\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "\n",
    "    return cleaned_sentences, tokenized_sentences  # คืนค่า 2 ค่า: ประโยคที่ทำความสะอาดแล้ว และการตัดคำ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100897f3-908a-4950-bc5e-fff47f73b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.11/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a648ebd6-182c-42dc-b8ac-145b6f42955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['cleantext'], tokenized_sentences = cleanText(x_test['body'])\n",
    "x_train['cleantext'], tokenized_sentences = cleanText(x_train['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c105265a-03ff-4d63-9a51-d1bfbb321fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vector(text):\n",
    "    tokens = word_tokenize(text, engine=\"newmm\")\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf46137-f5af-4b1a-bb5a-f0f80cc9fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = [get_average_vector(text) for text in x_train['cleantext']]\n",
    "X_test_vectors = [get_average_vector(text) for text in x_test['cleantext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02584b-6117-4097-8de4-357c7f0d164d",
   "metadata": {},
   "source": [
    "LogisticRegression ก่อนsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6324ad-a32e-4abc-b29b-3d742b5fb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f434f-e51a-4c97-9cee-4460829cdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c385a2-1c17-42d9-859a-da13ba1563d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "# # แสดง classification report\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # คำนวณค่า G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report พร้อมค่า G-mean\n",
    "# print(report)\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283f579-75bb-47ef-bd44-2e4ad7c0bc15",
   "metadata": {},
   "source": [
    "random ก่อน sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94d530-a76d-4f4e-b979-f49a7c635005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # ใช้ Random Forest เป็นโมเดล\n",
    "# RF = RandomForestClassifier(random_state=42)\n",
    "# RF.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4866e15-bfb6-4928-84cf-67789a201e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = RF.predict(X_test_vectors)\n",
    "\n",
    "# # แสดง classification report\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # คำนวณค่า G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report พร้อมค่า G-mean\n",
    "# print(report)\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e06b1f-5126-426e-a017-cee750f4dd0f",
   "metadata": {},
   "source": [
    "Model MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ac3c0-9e98-462f-9e02-6a1fc4ac76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b85e3-a9ae-4b27-adb7-da541e44e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define MLP model with different hyperparameters\n",
    "# mlp = MLPClassifier(\n",
    "#     hidden_layer_sizes=(128, 64),\n",
    "#     activation='relu',\n",
    "#     solver='adam',\n",
    "#     learning_rate_init=0.003,\n",
    "#     max_iter=100,\n",
    "#     batch_size=64,\n",
    "#     alpha=0.0001,\n",
    "#     random_state=42,\n",
    "#     early_stopping=False,  # Set to False to not stop early, so we can see full loss curve\n",
    "#     validation_fraction=0.2\n",
    "\n",
    "# )\n",
    "# y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c0e01-84c4-47f2-960c-86f51f1e1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model and capture loss curve\n",
    "# mlp.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a09f01-8f15-47eb-bcda-ed34df55acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = mlp.predict(X_test_vectors)\n",
    "\n",
    "# # แสดง classification report\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # คำนวณค่า G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report พร้อมค่า G-mean\n",
    "# print(report)\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72f944-079e-4d91-8935-086fa65386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate accuracy on the test set\n",
    "# accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "# print('Final MLP Accuracy:', accuracy_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91eeb5-e69e-4d19-9f03-d583eb7391d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9f85768-fa32-4889-9b18-cf2f65917e8e",
   "metadata": {},
   "source": [
    "SVM Model ก่อน Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60384f4e-391d-457d-a26f-bebd785ca3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import SVC classifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# # import metrics to compute accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a185c1-00b2-475c-b5be-9e1d5d5f40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiate classifier with default hyperparameters\n",
    "# svm_model = SVC(\n",
    "#     C=1.0,\n",
    "#     kernel='rbf',\n",
    "#     gamma='scale',\n",
    "#     degree=3,\n",
    "#     coef0=0.0,\n",
    "#     shrinking=True,\n",
    "#     probability=False,\n",
    "#     tol=0.001,\n",
    "#     cache_size=200,\n",
    "#     class_weight=None,\n",
    "#     verbose=False,\n",
    "#     max_iter=-1,\n",
    "#     decision_function_shape='ovr',\n",
    "#     break_ties=False,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246464f-467e-49bf-934e-b44f26552627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # แปลง y_resampled ให้เป็น 1 มิติ ก่อนส่งเข้าโมเดล\n",
    "# y_train = y_train.to_numpy().ravel()  # หรือใช้ reshape(-1) แทนก็ได้\n",
    "\n",
    "# svm_model.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce776681-1fdd-4503-bc42-45acb1bf66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = svm_model.predict(X_test_vectors)\n",
    "\n",
    "# # Print classification report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Calculate and print G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e806a-c5a6-4dd0-996d-e81980f875a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Load data\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "# X_train_vectors, X_test_vectors, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create an SVM classifier\n",
    "# svm = svm_model  # เปลี่ยน kernel ได้ตามต้องการ\n",
    "\n",
    "\n",
    "# # คำนวณ learning curve โดยลดความซับซ้อน\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     svm_model, X_resampled, y_resampled, cv=3, scoring='accuracy', n_jobs=1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "# )\n",
    "\n",
    "# # คำนวณค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานสำหรับ training และ test set\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# # วาดกราฟ Learning Curve\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "# plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training accuracy\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation accuracy\")\n",
    "\n",
    "# # เพิ่ม labels และหัวข้อ\n",
    "# plt.xlabel(\"Number of training samples\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Learning Curve That reduces complexity\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38419d-4426-43fe-bf6a-d2100e875931",
   "metadata": {},
   "source": [
    "Naive Bay Model ก่อน Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde81fff-63f5-476d-85a3-a0ca4344fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # นำเข้าไลบรารีที่จำเป็น\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680ba67-c1ca-4f71-adbb-2eea4400a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # สร้างโมเดล Gaussian Naive Bayes\n",
    "# model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c46ef3-a8cb-4418-8a40-0f8c03cdca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # กำหนดพารามิเตอร์ที่ต้องการปรับแต่ง (var_smoothing)\n",
    "# param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]}\n",
    "# # ใช้ GridSearchCV เพื่อหาค่าพารามิเตอร์ที่ดีที่สุด\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bf394-7781-4857-ae3b-5dd0e9965ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# y_train = y_train.to_numpy().ravel()  # หรือใช้ reshape(-1) แทนก็ได้\n",
    "\n",
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# grid_search.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276ecd5-dd3c-4f5a-966e-df04b55c662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # แสดงพารามิเตอร์ที่ดีที่สุด\n",
    "# print(f'Best Parameters: {grid_search.best_params_}')\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = grid_search.best_estimator_.predict(X_test_vectors)\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # คำนวณและแสดงค่า G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fb41c-4dd0-44d0-b46b-08a8f5dbc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ฝึกโมเดลด้วยชุดข้อมูลฝึก\n",
    "# model.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a46a3-6ea1-46d7-ad5b-18c286ec853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# y_train = y_train.ravel()  # หรือใช้ reshape(-1) แทนก็ได้\n",
    "\n",
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# grid_search.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30ccaf-fb4d-46e5-93f5-23f9e8deb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = model.predict(X_test_vectors)\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf92fc-4f2a-4595-93bd-a974db2d0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "# # ฟังก์ชันเพื่อสร้าง learning curve\n",
    "# train_sizes, train_scores, test_scores = learning_curve(model, X_train_vectors, y_train, cv=5, scoring='accuracy',\n",
    "#                                                         train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# # คำนวณค่าเฉลี่ยและค่าเบี่ยงเบนมาตรฐานของ accuracy บนชุดเทรนและทดสอบ\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# # สร้างกราฟ\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve (Naive Bayes)\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# # พล็อตค่า accuracy ของเทรนและเทส\n",
    "# plt.grid()\n",
    "\n",
    "# plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "# plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479013b5-01c1-4663-99e1-790cc7723570",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af19fb-fc12-46b7-bf19-941f92c19ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# # ตรวจสอบขนาดของ X_train_vectors และ y_train\n",
    "# print(\"Shape of X_train_vectors:\", np.shape(X_train_vectors))\n",
    "# print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# # ให้แน่ใจว่า y_train เป็นอาร์เรย์ NumPy\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# # ค้นหาคลาสส่วนใหญ่และคลาสส่วนน้อย\n",
    "# class_counts = np.bincount(y_train)\n",
    "# class_majority = np.argmax(class_counts)\n",
    "# class_minority = np.argmin(class_counts)\n",
    "\n",
    "# # แยกข้อมูลออกเป็นคลาสส่วนใหญ่และคลาสส่วนน้อย\n",
    "# boolean_mask_majority = (y_train == class_majority)\n",
    "# boolean_mask_minority = (y_train == class_minority)\n",
    "\n",
    "# X_majority = X_train_vectors[boolean_mask_majority]\n",
    "# y_majority = y_train[boolean_mask_majority]\n",
    "# X_minority = X_train_vectors[boolean_mask_minority]\n",
    "# y_minority = y_train[boolean_mask_minority]\n",
    "\n",
    "\n",
    "\n",
    "# # เลือกวิธีการปรับสมดุล\n",
    "# balance_method = \"undersample\"  # ใช้ \"undersample\" หรือ \"oversample\"\n",
    "\n",
    "# if balance_method == \"undersample\":\n",
    "#     # ลดขนาดคลาสส่วนใหญ่ให้เท่ากับคลาสส่วนน้อย\n",
    "#     X_majority_downsampled, y_majority_downsampled = resample(X_majority, y_majority,\n",
    "#                                                               replace=False,\n",
    "#                                                               n_samples=len(y_minority),\n",
    "#                                                               random_state=42)\n",
    "#     X_resampled = np.concatenate([X_majority_downsampled, X_minority])\n",
    "#     y_resampled = np.concatenate([y_majority_downsampled, y_minority])\n",
    "\n",
    "# elif balance_method == \"oversample\":\n",
    "#     # เพิ่มขนาดคลาสส่วนน้อยให้เท่ากับคลาสส่วนใหญ่\n",
    "#     X_minority_upsampled, y_minority_upsampled = resample(X_minority, y_minority,\n",
    "#                                                           replace=True,\n",
    "#                                                           n_samples=len(y_majority),\n",
    "#                                                           random_state=42)\n",
    "#     X_resampled = np.concatenate([X_majority, X_minority_upsampled])\n",
    "#     y_resampled = np.concatenate([y_majority, y_minority_upsampled])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5e2c4-7fca-4e61-9701-f6dcabe7f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_resampled), len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cd9a3-d563-481e-944e-ae4ea707f5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089c440-daf3-469c-b03b-0694790218b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaefef-0d73-44bb-86fe-3ea3c0452a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2130b4b-26ce-48dd-ab6a-4a6e284810c8",
   "metadata": {},
   "source": [
    "RUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2962c4-3c1d-45ac-b88c-946a0461ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbc95e-a233-428b-9b01-8ff5665dc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # แปลง X_train_vectors ให้เป็น numpy array หากยังไม่ได้ทำ\n",
    "# X_train_vectors = np.array(X_train_vectors)\n",
    "\n",
    "# # สร้างตัวอย่าง RUS\n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# # ทำการ under-sampling ข้อมูล\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_train_vectors, y_train)\n",
    "\n",
    "# # ตรวจสอบขนาดของข้อมูลที่ผ่านการ resample แล้ว\n",
    "# print(X_resampled.shape, y_resampled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d1d1f-9b30-4fb1-9336-8e6b41ead9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_resampled), len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ace4c9-8418-46b2-82b6-b6983136af9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "858aa5f4-0100-4dc7-8c1b-28c37b9f19b2",
   "metadata": {},
   "source": [
    "SMOGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1daf4-a42f-4257-95fd-47f8fd11cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install smogn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f35213-7c4a-4ba1-b21c-0bdc414d0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import smogn\n",
    "# import pandas as pd\n",
    "\n",
    "# # เตรียมข้อมูลต้นฉบับให้อยู่ในรูปแบบ DataFrame \n",
    "# data = pd.DataFrame(X_train_vectors)\n",
    "# data['target'] = y_train  # รวม target (y_train) เข้ากับข้อมูล feature (X_train_vectors)\n",
    "\n",
    "# # ใช้ SMOGN สำหรับการทำ oversampling\n",
    "# data_resampled = smogn.smoter(\n",
    "#     data,               # ข้อมูลที่มีทั้ง features และ target\n",
    "#     y='target',         # ชื่อคอลัมน์ของ target\n",
    "#     k=5,                # จำนวน k-nearest neighbors (สามารถปรับแต่งได้)\n",
    "#     samp_method=\"balance\"  # เลือกวิธีการสร้างตัวอย่าง (\"balance\" สำหรับสร้างตัวอย่างแบบสมดุล)\n",
    "# )\n",
    "\n",
    "# # แยกข้อมูลออกเป็น X และ y หลังจากการทำ oversampling\n",
    "# X_resampled = data_resampled.drop(columns=['target'])\n",
    "# y_resampled = data_resampled['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd61250-0cd9-43c0-8140-5fbae60e2558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d8b0a-b94f-4e7f-977d-b8a45f6e1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_resampled), len(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b95c5b-97f3-46dd-849d-b11dd70dd455",
   "metadata": {},
   "source": [
    "ROS oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1922e5-fd95-4c1c-b7f6-3621c2600f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829b85a2-4966-45f7-ad99-75af8bf9f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversample.fit_resample(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d3ef61-7840-4008-94b7-34468bb90fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12626 12626\n"
     ]
    }
   ],
   "source": [
    "print(len(X_resampled), len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db8ffa-07a4-4b73-b5cc-f2738f4b4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ฝึกโมเดลด้วยข้อมูลที่ undersampled\n",
    "# clf = RandomForestClassifier(random_state=42)\n",
    "# clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca763a9-dd82-4749-8142-9c3b7dfc11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ทำนายผลและคำนวณ G-mean\n",
    "# # y_pred = clf.predict(X_test)\n",
    "# gmean = geometric_mean_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e5e73-dc8f-42ac-ad27-454069bc7c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2e35e3e-82c2-483d-bbf9-bc6ecc56a664",
   "metadata": {},
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f4c3e-4176-4a83-b4f7-a7efab52f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c287d4-47d8-46aa-ab73-de1c49309fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9ba6f-dca3-4c08-93c8-e7772de1b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_resampled), len(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd06f01-f7a3-4f67-ab3a-45cde2e55eab",
   "metadata": {},
   "source": [
    "Model Naive Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf871584-2319-4c32-b902-6a23611eddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # นำเข้าไลบรารีที่จำเป็น\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abe8df-bd05-44ab-bb65-0dec9616049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # สร้างโมเดล Gaussian Naive Bayes\n",
    "# model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c44e7-746d-4fcb-8380-1a9569574b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # กำหนดพารามิเตอร์ที่ต้องการปรับแต่ง (var_smoothing)\n",
    "# param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]}\n",
    "# # ใช้ GridSearchCV เพื่อหาค่าพารามิเตอร์ที่ดีที่สุด\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557f0ed-0b72-4472-a2d8-b86b6af0bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# y_resampled = y_resampled.to_numpy().ravel()  # หรือใช้ reshape(-1) แทนก็ได้\n",
    "\n",
    "# # เทรนโมเดลด้วยข้อมูลที่เตรียมไว้\n",
    "# grid_search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0855653-59b7-447b-a357-f202d7e20dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # แสดงพารามิเตอร์ที่ดีที่สุด\n",
    "# print(f'Best Parameters: {grid_search.best_params_}')\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = grid_search.best_estimator_.predict(X_test_vectors)\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27300b17-092c-446f-95be-640872060d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "# # ฟังก์ชันเพื่อสร้าง learning curve\n",
    "# train_sizes, train_scores, test_scores = learning_curve(model, X_resampled, y_resampled, cv=5, scoring='accuracy',\n",
    "#                                                         train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# # คำนวณค่าเฉลี่ยและค่าเบี่ยงเบนมาตรฐานของ accuracy บนชุดเทรนและทดสอบ\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# # สร้างกราฟ\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve (Naive Bayes)\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# # พล็อตค่า accuracy ของเทรนและเทส\n",
    "# plt.grid()\n",
    "\n",
    "# plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "# plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d689c5f-7dc8-49c9-a6f3-6dcd2404402c",
   "metadata": {},
   "source": [
    "Model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b313a3-e451-4d32-9bae-2bae828cf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b0811-e9cb-489c-835f-507edd80626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifier with default hyperparameters\n",
    "svm_model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    degree=3,\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=0.001,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6d907-4dd1-4a35-86b6-3a35830a8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# แปลง y_resampled ให้เป็น 1 มิติ ก่อนส่งเข้าโมเดล\n",
    "y_resampled = y_resampled.to_numpy().ravel()  # หรือใช้ reshape(-1) แทนก็ได้\n",
    "\n",
    "svm_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245851c0-f32f-4170-8f80-c9dddcd736e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# ปิดการแจ้งเตือน DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "# make predictions on test set\n",
    "y_pred = svm_model.predict(X_test_vectors)\n",
    "# แสดงค่า G-mean และ Classification Report\n",
    "\n",
    "# คำนวณค่า G-mean\n",
    "gmean = geometric_mean_score(y_test, y_pred)\n",
    "# สร้าง classification report ในรูปแบบของ DataFrame\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# เพิ่มค่า G-mean ใน DataFrame\n",
    "report_df.loc['G-mean'] = [gmean, '', '', '']\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc89f5-6846-4dd5-a7f5-f387cefe5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load data\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "# X_resampled, X_test_vectors, y_resampled, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create an SVM classifier\n",
    "# svm = svm_model  # เปลี่ยน kernel ได้ตามต้องการ\n",
    "\n",
    "# # Generate learning curves\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     svm, X_resampled, y_resampled, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "# )\n",
    "\n",
    "# # Calculate mean and standard deviation for training and test sets\n",
    "# train_mean = np.mean(train_scores, axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)\n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# # Plot learning curves\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
    "# plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
    "# plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1feaae-07b3-4dbe-b28f-3ff81f28d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load data\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_resampled, X_test_vectors, y_resampled, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# คำนวณ learning curve โดยลดความซับซ้อน\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    svm_model, X_resampled, y_resampled, cv=3, scoring='accuracy', n_jobs=1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "# คำนวณค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานสำหรับ training และ test set\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# วาดกราฟ Learning Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training accuracy\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation accuracy\")\n",
    "\n",
    "# เพิ่ม labels และหัวข้อ\n",
    "plt.xlabel(\"Number of training samples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Learning Curve That reduces complexity\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621896b-17ff-41c2-a723-5df3e37bd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Define the hyperparameters to tune\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100, 1000],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma': ['scale', 'auto']  # only needed for 'rbf' and 'poly'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb6aff-9287-4693-8fa6-0cb7f01b98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "# grid_search.fit(X_resampled, y_resampled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b0c2f-6cb9-4c21-aca5-f581e4b4e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# linear_svc = LinearSVC()  # Assign it to a variable called linear_svc\n",
    "# model = linear_svc  # Now you can use the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56683a9d-3464-4661-9cd7-79263aa7df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# # Initialize the model\n",
    "# linear_svc = LinearSVC()\n",
    "\n",
    "# # Fit the model with training data (this step is crucial)\n",
    "# linear_svc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # Now, you can use the score() method after fitting the model\n",
    "# print('Training set score: {:.4f}'.format(linear_svc.score(X_resampled, y_resampled)))\n",
    "# print('Test set score: {:.4f}'.format(linear_svc.score(X_test_vectors, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a53dc3-0133-494d-a1f2-64bd82329551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8240388-f08c-4731-b95d-60aeeb5baf69",
   "metadata": {},
   "source": [
    "Model Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0d3bf-b033-4910-af4a-6920beb4ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1a3c2-6ac8-474d-89b2-21bb6bc9e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression(solver='lbfgs', max_iter=100, random_state=42)\n",
    "# clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913e4d8-e095-41f9-9ea1-f33ed96c2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(X_test_vectors)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9dd8b-2e1c-4707-bfd1-c30b1c3bf58a",
   "metadata": {},
   "source": [
    "Model Landom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2a6a0-d417-4f19-a0fe-6fac0a795cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # ใช้ Random Forest เป็นโมเดล\n",
    "# RF = RandomForestClassifier(random_state=42)\n",
    "# RF.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423beba-23a7-486d-b6c7-2c020ea0461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = RF.predict(X_test_vectors)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e660d8-64f3-4aee-a137-e46b968571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896c711-acd3-4fae-b506-aea5dc4c719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     clf.max_iter = 100 * i\n",
    "#     clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "#     # คำนวณ loss บน training set และ validation set\n",
    "#     train_loss = log_loss(y_resampled, clf.predict_proba(X_resampled))\n",
    "#     val_loss = log_loss(y_test, clf.predict_proba(X_test_vectors))\n",
    "    \n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "# # แสดงกราฟ\n",
    "# plt.plot(range(1, 11), train_losses, label='Training Loss')\n",
    "# plt.plot(range(1, 11), val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epochs (x10)')\n",
    "# plt.ylabel('Log Loss')\n",
    "# plt.title('Learning Curve - Loss')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127533b-74b6-42bd-a529-f3e938e558c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     RF.max_iter = 10 * i\n",
    "#     RF.fit(X_resampled, y_resampled)\n",
    "    \n",
    "#     # คำนวณ loss บน training set และ validation set\n",
    "#     train_loss = log_loss(y_resampled, RF.predict_proba(X_resampled))\n",
    "#     val_loss = log_loss(y_test, RF.predict_proba(X_test_vectors))\n",
    "    \n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "# # แสดงกราฟ\n",
    "# plt.plot(range(1, 11), train_losses, label='Training Loss')\n",
    "# plt.plot(range(1, 11), val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epochs (x10)')\n",
    "# plt.ylabel('Log Loss')\n",
    "# plt.title('Learning Curve - Loss')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bee13-d388-4a25-bada-4e1d2e1c4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # ประเมินโมเดลด้วย K-Fold Cross-Validation\n",
    "# scores = cross_val_score(clf, X_resampled, y_resampled, cv=5)  # 5-fold cross-validation\n",
    "# print(f\"Cross-validation scores: {scores}\")\n",
    "# print(f\"Mean cross-validation score: {scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5602e37-d67a-4f5c-9b73-3d9d2cb165b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ประเมินโมเดลด้วย K-Fold Cross-Validation\n",
    "# scores = cross_val_score(RF, X_resampled, y_resampled, cv=5)  # 5-fold cross-validation\n",
    "# print(f\"Cross-validation scores: {scores}\")\n",
    "# print(f\"Mean cross-validation score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d224b58-e87d-4ed8-a7ba-bea197ae9bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f7655-eb48-4684-be6b-d168a2b92dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dadb220d-f27f-44a8-8109-a70a3f61ecdb",
   "metadata": {},
   "source": [
    "MLP model หลัง sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da2e44-d5b4-4902-bdcf-a48f5416bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e1ab2-1e42-482e-b97d-eaf907f258b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define MLP model with different hyperparameters\n",
    "# mlp = MLPClassifier(\n",
    "#     hidden_layer_sizes=(128, 64),\n",
    "#     activation='relu',\n",
    "#     solver='adam',\n",
    "#     learning_rate_init=0.003,\n",
    "#     max_iter=100,\n",
    "#     batch_size=64,\n",
    "#     alpha=0.0001,\n",
    "#     random_state=42,\n",
    "#     early_stopping=False,  # Set to False to not stop early, so we can see full loss curve\n",
    "#     validation_fraction=0.2\n",
    "\n",
    "# )\n",
    "# y_resampled = y_resampled.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254428b-abca-4fe9-a153-b2b8abe150dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model and capture loss curve\n",
    "# mlp.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbcf35-346e-47b8-8a85-cd1411738ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# # ทำนายผลบนชุดข้อมูลทดสอบ\n",
    "# y_pred = mlp.predict(X_test_vectors)\n",
    "\n",
    "# # แสดง classification report\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # คำนวณค่า G-mean\n",
    "# gmean = geometric_mean_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# # แสดงผลลัพธ์ classification report พร้อมค่า G-mean\n",
    "# print(report)\n",
    "# print(f\"G-Mean: {gmean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702cf75-63f6-4ae0-82d3-d1e45d57671a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
